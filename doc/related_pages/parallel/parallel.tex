%%%%%%%%%%%%%%%%%%%%%definitions%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\input{../header.tex}
\input{../newcommands.tex}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%DOCUMENT%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{document}
%\preprint{}

\title{The parallel derivative on structured grids}
\author{M.~Wiesenberger and M.~ Held}

\maketitle

\abstract{
This write-up shows how we numerically treat parallel derivatives in a non field
aligned coordinate system. It is mainly based on References~\cite{Hariri2014,Held2016,Stegmeir2017} and contains parts from References~\cite{WiesenbergerPhD, HeldPhD}
}
\section{Discretization of parallel derivatives} \label{sec:parallel}
We introduce the method
and discuss some problems arising from the boundaries of the computational domain.

\subsection{The flux coordinate independent approach} \label{sec:parallela}
Given is a vector field $\vec v(R,Z)$ in cylindrical coordinates $R,Z,\varphi$ independent of $\varphi$ and we want to
discretize the derivative $\vec v \cdot\nabla f \equiv \nabla_\parallel f$.
The vector field $\vec v$ might be the magnetic unit vector field but the algorithm works
for any vector field $\vec v$ with $v^\varphi\neq 0$, in particular $\vec v$ does not need
to have unit length.

We begin with the formulation of a field-aligned discretization.
To every smooth vector field $\vec v(\vec x)$ there is a unique curve of which the
tangent in a point $p$ is the value of $\vec v(p)$ at that point. It is given by
the solution of the differential equation
\begin{align}
  \frac{\d z^i}{\d s} = v^i(\vec z)|_{\vec z(s)}
    \label{eq:integralcurve}
\end{align}
where $z^i$ is one of $(R, Z, \varphi)$ and $v^i$ are the contravariant components
of $\vec v$ in cylindrical coordinates.
Note here that $s$ does NOT necessarily denote the distance
(especially since we do not require the existence of a metric at this point).
Moreover, by definition we have
\begin{align}
    \frac{\d f(\vec z(s))}{\d s} = \vec v\cdot \nabla f|_{\vec z(s)}
    \label{}
\end{align}
along a field line parameterized by $s$.
This means that instead of $\vec v \cdot \nabla f$ we can choose to discretize ${\d f}/{\d s}$.

Let us divide the $\varphi$ direction into $N_\varphi$ equidistant planes of
$\Delta \varphi$. Unfortunately, from Eq.~\eqref{eq:integralcurve} we cannot easily determine
$\Delta s$ for given $\Delta \varphi$. However, we know that $\vec v\cdot\nabla f = v^\varphi \frac{\vec v}{v^\varphi}\cdot\nabla f$,
thus we can choose to
discretize
\begin{align}
    \frac{\d f(\vec z(t))}{\d t} = \frac{\vec v}{v^\varphi}\cdot \nabla f|_{\vec z(t)}
\end{align}
and in the end multiply by $v^\varphi$ to get a discretization for $\vec v\cdot \nabla f$.
We have
\begin{align}
    \frac{\d z^i}{\d t} = \frac{v^i}{v^\varphi}
    \label{}
\end{align}
In this case $\d\varphi/\d t = 1 \Rightarrow t=\varphi$ and we get
\begin{subequations}
\begin{align}
    \frac{\d R}{\d\varphi}&= \frac{v^R}{v^\varphi},\\ %\frac{R}{I}\frac{\partial\psi}{\partial Z},\\
    \frac{\d Z}{\d\varphi}&=\frac{v^Z}{v^\varphi}%-\frac{R}{I}\frac{\partial\psi}{\partial R}.
\end{align}
\label{eq:fieldline}
\end{subequations}
We integrate Eqs.~\eqref{eq:fieldline} from $\varphi=0$ to $\varphi=\pm \Delta \varphi$
with initial condition
\begin{align}
    (R(0), Z(0)) = (R, Z).
    \label{}
\end{align}
Let us characterize the solution $(R(\pm \Delta \varphi), Z(\pm \Delta \varphi))$ to Eqs.~\eqref{eq:fieldline} as the flow generated by $\vec v/v^\varphi$
\begin{align}
    \Tpm\vec z \equiv \Tpm[R, Z, \varphi]:= ( R(\pm \Delta\varphi), Z( \pm \Delta\varphi), \varphi\pm\Delta \varphi),
    \label{}
\end{align}
Obviously we have $\Tm\circ\Tp = \Eins$, but $\Tpm$ is not necessarily unitary since $\vec v/v^\varphi$ is in general
not divergence free.

We now propose a centered discretization for the parallel derivative
\begin{align}
    \nabla_\parallel f \equiv \frac{df}{ds} = v^\varphi\frac{df}{d\varphi}
    \rightarrow v^\varphi(\vec z) \frac{f\left(T_{\Delta\varphi}^+\vec z\right)-f\left(T_{\Delta\varphi}^-\vec z\right)}{2\Delta\varphi},
  \label{eq:paralleldis}
\end{align}
which is equivalent to Reference~\cite{Hariri2014}.

Since the $R$ and $Z$ coordinates are still discretized in the dG framework we note that in our work
the interpolation of $f$ on the transformed points $\Tpm\vec z$
is naturally given by interpolating the base polynomials.
Let us for a moment omit the $Z$ coordinate for ease of notation.
If $(R_{nj}, \varphi_k)$ are the grid points,
we call $(R^+_{nj}, \varphi_{k+1}) := \Tp[R_{nj}, \varphi_k]$ and
$(R_{nj}^-, \varphi_{k-1}) := \Tm[R_{nj}, \varphi_k]$ the transformed coordinates along
the field lines. We then have
\begin{subequations}
\begin{align}
    f(\Tp\vec z) = f( R^+_{nj}, \varphi_{k+1}) = \bar f_{k+1}^{ml}p_{ml}(R^+_{nj}) =: (I^+)_{nj}^{ml}f_{(k+1)ml} , \\
    f(\Tm\vec z) = f( R^-_{nj}, \varphi_{k-1}) = \bar f_{k-1}^{ml}p_{ml}(R^-_{nj}) =: (I^-)_{nj}^{ml}f_{(k-1)ml} , 
\end{align}
\label{eq:interpolation}
\end{subequations}
where the backward transformations of $\bar{ \vec f}$ are hidden in $I$.
Thus, the interpolation of all the necessary points can simply be written as a matrix-vector product, where the interpolation matrices $I^+$  and $I^-$ are independent of time since
the field lines are constant in time. The order of this interpolation is given by $P$, the number of polynomial coefficients.
A consistency check is the relation $I^+\circ I^- = \Eins$.

The discretization~\eqref{eq:paralleldis} can now be written as a matrix vector product
\begin{align}
    \nabla_\parallel f \rightarrow H \circ \left[ \Eins^+\otimes I^+ - \Eins^- \otimes I^-  \right] \vec f, 
    \label{}
\end{align}
where $H$ is the diagonal matrix that contains the entries $v^\varphi(\vec z)/2\Delta\varphi$.
This discretization is not skew-symmetric since the
field lines are not volume-preserving, or~$(I^+)^\mathrm{T} \neq I^-$.
In fact, the adjoint of the parallel derivative is
\begin{align}
    \nabla_\parallel^\dagger f = - \nabla\cdot(\vec v\ f ) \neq -\nabla_\parallel f.
    \label{}
\end{align}
Note that with this relation we can define the parallel
diffusion operator as
\begin{align}
    \Delta_\parallel := -\nabla_\parallel^\dagger \nabla_\parallel = (\nabla\cdot \vec{ \hat v}) \nabla_\parallel + \nabla_\parallel^2 , 
    \label{}
\end{align}
which is indeed the parallel part of the full Laplacian $\Delta = \nabla\cdot( \vec{ \hat v} \nabla_\parallel + \nabla_\perp)$.
$\vec{ \hat v} $ is the unit vector $\vec v/ |\vec v|$.

Note that the second order derivative $\nabla_\parallel^2$ CANNOT be
discretized using
\begin{align}
    \frac{\d^2 f}{\d s^2} \rightarrow
    (v^\varphi)^2 \frac{f_{k+1} - 2f_k + f_{k-1} }{\Delta\varphi^2} \text{   False Friend!!}
    \label{}
\end{align}
where $f_k = f(\vec z_k)$ with $\vec z_k = (R,Z,\varphi_k)$ and $f_{k\pm 1} := f(\Tpm \vec z_k)$.
The formula is deceptive since it misses the terms stemming from the chain rule:
 $\nabla_\parallel \bhat \cdot \nabla f =  \bhat\bhat : \nabla\nabla f + (\nabla_\parallel \bhat) \cdot \nabla f$.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Change of coordinates}
In principle the above considerations hold in any
coordinate system $\eta,\zeta,\varphi$, since the directional derivative is
an intrinsic operation.
The only question is how to integrate the field lines in the
$\eta, \zeta,\varphi$ system
since we assumed that our vector field $\vec v(\vec x)$ was given
analytically in
cylindrical coordinates. There are two possibilities.
First, interpolate $R(\zeta_i, \eta_i), Z(\zeta_i, \eta_i)$ for
all $i$, then integrate $\vec v$ in $(R,Z)$ space and finally use
Newton iteration to find $\zeta(R^\pm_i, Z^\pm_i), \eta(R^\pm_i, Z^\pm_i)$.
The downside here is that it is difficult to tell when and where the fieldline leaves the simulation domain. (However this is true also for the
following approach, See Section~\ref{sec:boundary})

The second possibility (the one currently implemented)
is to integrate entirely in the
transformed coordinate system $\zeta, \eta, \varphi$.
The magnetic field can be easily transformed since we have the
Jacobian of the coordinate transformation
\begin{align}
    v^\zeta(\zeta, \eta) &= \left(\frac{\partial \zeta}{\partial R} v^{R} + \frac{\partial \zeta}{\partial Z}v^Z\right)_{R(\zeta, \eta), Z(\zeta, \eta)} \\
    v^\eta(\zeta, \eta) &= \left(\frac{\partial \eta}{\partial R} v^{R} + \frac{\partial \eta}{\partial Z}v^Z\right)_{R(\zeta, \eta), Z(\zeta, \eta)} \\
    v^\varphi(\zeta, \eta) &= v^\varphi({R(\zeta, \eta), Z(\zeta, \eta)})
    \label{eq:field_trafo}
\end{align}
The fieldline equations~\eqref{eq:fieldline} are still
\begin{subequations}
\begin{align}
\frac{\d \zeta}{\d\varphi} &= \frac{v^\zeta}{v^\varphi}\\
\frac{\d \eta}{\d\varphi} &= \frac{v^\eta}{v^\varphi}
\end{align}
\label{eq:fieldlines}
\end{subequations}
The issue here is that when integrating fieldlines we
have to interpolate the vector field $\vec v$ at arbitrary points
instead of simply evaluating the exact values.
However, the interpolation error vanishes with order $P$ in the
perpendicular plane so in order to mitigate this error
we transform $\vec v$ on a finer grid/higher order polynomials for more accurate
integration.
Apart from the issue of how to get the transformed vector field
the remaining algorithm for $\vec v\cdot\nabla$ is entirely unchanged
and Eq.~\eqref{eq:paralleldis} still holds.

\subsection{Boundary conditions} \label{sec:boundary}
The question is what to do when a fieldline intersects with the boundary
of the simulation domain before reaching the next plane.
Boundary conditions are formulated by either setting a value
on the boundary of the domain (Dirichlet) or by fixing
the derivative perpendicularly to the boundary (Neumann), or
a combination of both ( Robin).

One approach for Dirichlet boundary conditions
is to find the exact place where the fieldline intersects the boundary.
We have to find
$\varphi_b$ such that the result of the integration of Eq.~\eqref{eq:fieldline} from
$0$ to $\varphi_b$ lies on the boundary.
The angle $\varphi_b$ can be found by a bisection algorithm knowing that $0<\varphi_b < \Delta\varphi$.
This kind of procedure is known as a shooting method.
Another possibility is to trick the fieldline integrator into finding the point for us.
We do this by setting $\vec v \equiv 0$ on all points outside the simulation box, which
makes the ODE integrator stop once it crosses the domain boundary.
This works fairly well with the adaptive embedded Runge Kutta method that we use.
However, the problem with this procedure in practice is the small
distance between the starting point and the point where the corresponding
fieldline intersects the boundary. This seriously deteriorates the
CFL condition. (To ease the CFL condition
was the reason to devise the algorithm in the first place)

One problem with Neumann boundaries is that they usually prescribe
derivatives perpendicular to the boundary
while the fieldlines are in general not perpendicular to the boundary.

The \textbf{approach we currently adopted} is to introduce ghostcells at the
places where fieldlines end. The value of the ghostcells are
as if we Fourier transformed the fields on the simulation domain
with the correct boundary conditions and thus have a periodic
extension of the fields beyond the boundaries.
For example, for Neumann boundary
conditions the field is effectively mirrored at the boundary, while for
Dirichlet boundary conditions the values are the negative mirror image.
This is very easily implemented (at least as long as we only allow
homogeneous Boundary conditions) since we don't actually have to
perform the Fourier transformation, we only need to mirror the end
coordinates at the boundary and then choose either the positive (Neumann) or
negative (Dirichlet) interpolation.

The above procedure works for cylindrical coordinates where we can
evaluate and thus integrate the vector field $\vec v$ even outside the domain.
This is unfortunately not true for transformed coordinates.
For now we have to rely on the fieldlines being aligned to the
boundary in these cases to avoid boundary conditions altogether.
This is possible in \textsc{Feltor} at least for the closed field line region
(read the geometries section).

\subsection{Avoiding boundary conditions in non-aligned systems} \label{sec:avoid}

When computing in non-aligned coordinate systems
one idea to avoid boundary conditions
is to simply cut the contribution from field lines
that leave the computational domain. While this might work in practice
it is \textbf{highly unclear} what numerical and physical side-effects this procedure might have.

Another solution would be to change the
vector field $\vec v$ and only retain the toroidal part of $\vec v$ on the
boundary ( $v^R|_{\partial\Omega} = v^Z|_{\partial\Omega} =0$). The fieldlines then have a kink on the boundary $\partial\Omega$.
On the other hand we can implement boundary conditions consistent with
the perpendicular ones since the fieldlines never leave the domain.
We simply interpolate the quantity to derive on the inner side of the
domain boundary (Neumann conditions = "No boundary condition") or
set the value to zero (Dirichlet condition).
\textbf{Unfortunately, when testing this procedure with an analytical solution
the error does not converge neither for Dirichlet nor for Neumann.}

\subsection{Poloidal limiters}
A poloidal limiter can simply be implemented via a boundary condition in $\varphi$.
As long as the form of the limiter is aligned with a flux-function we do not have to
integrate a field line in order to determine which points lie in the
limiter-shadow. It is therefore straightforward to implement ghost-cells
in that case.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{The adjoint methods}
\subsection{A grid refinement approach}
The idea is to discretize the operation $\nabla\cdot( \vec v .)$ by
taking the adjoint of the discretization for $\nabla_\parallel$ i.e. Eq.~\eqref{eq:paralleldis}.
Remember that the adjoint of a matrix
involves the volume element (including dG weights). This means that after you've transposed the
parallel derivative Eq.~\eqref{eq:paralleldis}, simply bracket the result
by $1/\sqrt{g}$ and $\sqrt{g}$ to get the adjoint.

While the idea of simply transposing the discretization matrices sounds appealing the problem
is that the resulting discretization does not converge.
One idea to solve this problem \cite{Stegmeir2017} is
to bracket the parallel derivative by interpolation ($Q$) and
projection ($P$) matrices:
\begin{align}
    \nabla^c_\parallel &= P\nabla_\parallel^f Q \\
    \nabla^{c\dagger}_\parallel &= P \nabla^{f\dagger}_\parallel Q
    \label{eq:sandwich}
\end{align}
where $f$ and $c$ denote fine and coarse grid respectively.
In this way the projection integrals
\begin{align*}
    \int\dV (\nabla_\parallel f) p_i(x)p_j(y)
    \label{}
\end{align*}
are computed more precisely.
The size of the fine grid should therefore be as large as
possible.
We first notice that one interpolation matrix can be absorbed
in the parallel derivative since this also consists of
interpolation operations.
\begin{align}
    \nabla^c_\parallel &= P\nabla_\parallel^{fc} \\
    \nabla^{c\dagger}_\parallel &= \nabla^{fc\dagger}_\parallel Q
    \label{eq:sandwich}
\end{align}
Note that the matrix-matrix multiplications in Eq.~\eqref{eq:sandwich} can
be precomputed and stored. The memory requirements
in the final computations are
therefore the same  as in the old version. (Not entirely, since
the diagonal $v^\varphi/\Delta \varphi$ matrix does not commute with $Q$ or $P$).



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Some Thoughts}
In order to understand what the adjoint operators do let us denote $\Tp$ as the push-forwward operator. Then we have
\begin{align}
    \int f(\vec x) \Tp h(\vec x) \sqrt{g(\vec x)}\d^3x% \\
    %=  \int f(\vec x) h(\Tm \vec x)\sqrt{g(\vec x)}\d^3x \\
    %=  \int f(\Tp \vec x') h(\vec x')\sqrt{g(\Tp \vec x')}J^{-1}( \Tp\vec x') \d^3x' \\
    =  \int \frac{1}{\sqrt{g(\vec x')}}\Tm\left[J^{-1}(\vec x')\sqrt{g(\vec x')}f(\vec x')\right] h(\vec x')\sqrt{g(\vec x')}   \d^3x' \nonumber \\
    \equiv  \int (\Tp)^\dagger\left[f(\vec x)\right] h(\vec x)\sqrt{g(\vec x)}   \d^3x
    \label{}
\end{align}
$J$ is the determinant of the Jacobian $\partial(\vec x')/\partial(\vec x)$ with $\vec x' = \Tm \vec x$.
In the last step we simply replaced the dummy variable $\vec x'$ with $\vec x$ again and identified the relevant terms
as the adjoint operator:
\begin{align}
    (\Tp)^\dagger f(\vec x ) := \frac{1}{\sqrt{g(\vec x)}} \Tm\left[\sqrt{g(\vec x)} J^{-1}(\vec x) f(\vec x) \right]
    \label{}
\end{align}
This means that numerically the adjoint of the push-forward
operator should be a valid discretization of its inverse.
Note that $\sqrt{g}J^{-1}(\vec x) = \sqrt{g'(\Tm \vec x)}$.
With this we can write
\begin{align}
    (\Tp)^\dagger f(\vec x ) := \sqrt{\frac{g'(\vec x)}{g(\vec x)}} \Tm\left[f(\vec x) \right]
    \label{}
\end{align}
Note that $\Tp [fh] = \Tp f \Tp h$ might not
hold on the discrete level. Also the question is how $J$ enters
on the discrete level. We have to multiply $\sqrt{g}$ artificially when we form the adjoint.
Theoretically $J$ could be hidden somehow when we integrate the fieldlines, so the information could be contained in the discrete version? (Maybe in the back-projection?)

If we integrate streamlines of the any vector field $\vec v$, then we have
\begin{align}
    \frac{\d J}{\d \varphi} = J(\vec x ) \nabla\cdot\vec v
    \label{}
\end{align}
along these streamlines~\cite{something}.
If the streamlines are divergence free, we have $J=1$.
A numerical test could be ( if we neglect the volume form in the adjoint)
\begin{align}
    (\Tp)^\dagger \left[J(\vec x)\Tp f(\vec x)\right] - f(\vec x) = 0
    \label{}
\end{align}
The numerical computation of $J$ might a bit tricky at the boundaries.
In a flux-aligned $\zeta, \eta$ it should be feasible but in cylindrical coordinates I don't know how. Maybe we can simply cut the last few cells before the boundary.
Even easier might be
\begin{align}
    \left(\Tp\right)^\dagger J(\vec x ) = 1
    \label{}
\end{align}

Finally, let us assume that $\vec v = \bhat$ is the magnetic field
unit vector. Then we have analytically $\nabla\cdot \vec B= \nabla_\parallel^\dagger B = 0$.
Numerically, this is true if we have
\begin{align}
\left(\Tp\right)^\dagger B^\varphi  = \left(\Tm\right)^\dagger B^\varphi = B^\varphi
\end{align}


\section{Algorithm}
Given are the components $v^i(R,Z)$ for $i\in\{R,Z,\varphi\}$ and a compuational grid (in the following the ``coarse grid``)
\begin{itemize}
  \item generate a fine grid by multiplying the cell numbers of the given coarse grid topologcially (metric and Jacobian of the fine grid are not needed)
  \item integrate the fieldlines for the fine grid:
    \begin{itemize}
      \item evaluate the starting points on the \textbf{coarse} grid in computational space
      \item For a curvilinear grid set up a (higher order, currently 7) grid for the
        interpolation of the vector components $v^i$ and push forward the vector components
        to the curvilinear coordinate system
      \item Integrate the fieldline equations
\begin{subequations}
\begin{align}
\frac{\d \zeta}{\d\varphi} &= \frac{v^\zeta}{v^\varphi}\\
\frac{\d \eta}{\d\varphi} &= \frac{v^\eta}{v^\varphi}
\end{align}
\label{eq:fieldlines_converted}
\end{subequations}
    with the given starting points from $\varphi=0$ until $\varphi = \pm\Delta \varphi$. (Currently we use a Prince-Dormand method with stepsize control for this step).
      \item create an interpolation matrix that interpolates from the coarse grid
        to the fine grid
      \item use the interpolation matrix to generate the plus/minus points for the fine grid
    \end{itemize}
  \item create the interpolation matrices that interpolate from the given coarse grid
    to the plus/minus points of the fine grid
  \item create a projection matrix that projects from the fine grid to the coarse grid
  \item compute the matrix-matrix multiplications $P\cdot I^\pm$ as well as their transposes
  \item finally pullback $v^\varphi$ on the coarse grid in the desired coordinates
\end{itemize}

\paragraph{Notes on the MPI implmentation}
It is advantageous to construct $\nabla_\parallel^{fc}$
as s row-distributed matrix with global indices.
This is because a column distributed matrix can be easily (without mpi-communication) multiplied
with a row distributed matrix especially if the indices are global indices.
Each process just multiplies its local matrices.
\begin{align}
M = C\cdot R
\end{align}
This is not true if we started with a column distributed matrix.
The result is then a row distributed matrix with global indices.
From the global indices the gather map/matrix and the local
indices can be constructed.
We note here that we even don't need to construct the gather matrix
for $\nabla_\parallel^{fc}$, only the one for $\nabla_\parallel^c$ is
needed.
\section{Field aligned initialization} \label{sec:parallelc}

An important aspect of our simulations is a judicious initialization of the
fields. We want structures to be field-aligned in the beginning of the simulation with
a possible modulation along the direction of the field line.
If a Gaussian shape is used, we call $\sigma_\parallel$ the extension in parallel
direction and write
\begin{align}
    f_0(R,Z,\varphi) = F(R,Z,\varphi) \exp\left( - \frac{(\varphi-\varphi_0)^2}{2\sigma_\parallel^2}\right),
    \label{eq:parallelInit}
\end{align}
where $F$ is a function that is invariant under the field line transformations
\begin{subequations}
\begin{align}
    \Tp F(\vec z) &= F( \Tp \vec z) \overset{!}{=} F(\vec z) \text{ (pull-back), } \\
    \Tm F(\vec z) &= F( \Tm \vec z) \overset{!}{=} F(\vec z) \text{ (push-forward). } 
\end{align}
\label{}
\end{subequations}
We can use these relations to construct aligned structures
by active transformations of some given field.
Our idea is to initialize a two-dimensional field $F(R,Z, \varphi_k)$ in a given plane $k$ and
transform this field to all other planes using the recursive relations
\begin{subequations}
\begin{align}
    F( R, Z, \varphi_{k+1}) = \Tm F( R, Z, \varphi_{k+1}) = F(R^-, Z^-, \varphi_k), \\
    F( R, Z, \varphi_{k-1}) = \Tp F( R, Z, \varphi_{k-1}) = F(R^+, Z^+, \varphi_k),
\end{align}
    \label{eq:recursiveInit}
\end{subequations}
which is the statement that $F$ in the next plane equals the push-forward
and $F$ in the previous plane equals the pull-back of $F$ in the current plane.
Note here that Eq.~\eqref{eq:interpolation} applies for the required interpolation
procedures.



\section{Numerical test programs}
The essential test programs for the parallel derivative are located in
\code{
path/to/feltor/inc/geometries}.
\code{ ds\_t.cu} and \code{ ds\_mpit.cu} test the cylindrical grid for shared and distributed memory
systems. \code{ ds\_curv\_t.cu} and \code{ ds\_curv\_mpit.cu} test the implementation
on a flux-aligned grid.
The magnetic field in \textsc{Feltor} is given by
\begin{align}
  \vec B = \frac{R_0}{R}( I(\psi_p) \hat e_\varphi + \nabla\psi_p \times\hat e_\varphi)
\end{align}
This gives rise to magnetic field strength and components
\begin{align}
  B = \frac{R_0}{R} \sqrt{ I^2 + \left( \nabla\psi_p \right)^2} \\
  B^R = \frac{R_0}{R}\frac{\partial\psi_p}{\partial Z} \quad
  B^Z = -\frac{R_0}{R}\frac{\partial\psi_p}{\partial R}\quad 
  B^\varphi = \frac{R_0I}{R^2} \\
  \nabla \cdot\bhat = -\nabla_\parallel \ln B = -\frac{R_0}{RB^2} [B, \psi_p]  
  \label{}
\end{align}
where $[.,.]$ is the Poisson bracket.
\subsection{Cylindrical grid and circular flux surfaces}
A very simple non-trivial choice for the poloidal flux is
\begin{align}
  \psi_p = \frac{1}{2} \left( (R-R_0)^2 + Z^2 \right) \equiv \frac{1}{2} r^2
  \label{eq:circular}
\end{align}
for which
\begin{align}
  \vec b^p &= \frac{1}{\sqrt{I^2 + r^2}} \begin{pmatrix} Z \\ -(R-R_0)\end{pmatrix} \\
  b^\varphi &= \frac{1}{\sqrt{I^2 + r^2}} I/R \\
  \nabla\cdot \bhat &= \frac{Z}{R(I^2 + r^2)}
  \label{}
\end{align}
for the poloidal and toroidal parts of the magnetic unit vector.
We choose $R_0 = 10$ and $I=20$ in order to keep the q-factor for the $r=1$ flux surface at $2$.
We set up a domain
$R\in[R_0-1, R_0+1]$,
$Z\in[-1,1]$ and
$\varphi \in [0,2\pi]$ and choose
\begin{align}
  f(R,Z,\varphi) = ((R-R_0)^2 + Z^2)\sin(\varphi)\\
  \bhat \cdot \nabla f= b^\varphi \cos(\varphi)
  \label{}
\end{align}
This is advantageous since the solution is correct even if we modify the $\bhat$ field
to be toroidal on the boundary of the domain in order to avoid boundary conditions.
Also the function is parabolic, which means that dG polynomials of degree greater than $2$
should be exact.
\subsection{Curvilinear grid}





%..................................................................
\bibliography{../references}
%..................................................................


\end{document}

